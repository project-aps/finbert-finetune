{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "454837e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, pipeline\n",
    "import torch\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fe7e329c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09113513",
   "metadata": {},
   "outputs": [],
   "source": [
    "# download model from hugging face\n",
    "model_name = \"project-aps/finbert-finetune\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name).to(device)\n",
    "model.eval()  # set model to evaluation mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68a2ed7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "===========================================================================================================================================================\n",
       "Layer (type:depth-idx)                                  Input Shape               Output Shape              Param #                   Trainable\n",
       "===========================================================================================================================================================\n",
       "BertForSequenceClassification                           --                        [1, 3]                    --                        True\n",
       "├─BertModel: 1-1                                        [1, 128]                  [1, 768]                  --                        True\n",
       "│    └─BertEmbeddings: 2-1                              --                        [1, 128, 768]             --                        True\n",
       "│    │    └─Embedding: 3-1                              [1, 128]                  [1, 128, 768]             23,440,896                True\n",
       "│    │    └─Embedding: 3-2                              [1, 128]                  [1, 128, 768]             1,536                     True\n",
       "│    │    └─Embedding: 3-3                              [1, 128]                  [1, 128, 768]             393,216                   True\n",
       "│    │    └─LayerNorm: 3-4                              [1, 128, 768]             [1, 128, 768]             1,536                     True\n",
       "│    │    └─Dropout: 3-5                                [1, 128, 768]             [1, 128, 768]             --                        --\n",
       "│    └─BertEncoder: 2-2                                 [1, 128, 768]             [1, 128, 768]             --                        True\n",
       "│    │    └─ModuleList: 3-6                             --                        --                        85,054,464                True\n",
       "│    └─BertPooler: 2-3                                  [1, 128, 768]             [1, 768]                  --                        True\n",
       "│    │    └─Linear: 3-7                                 [1, 768]                  [1, 768]                  590,592                   True\n",
       "│    │    └─Tanh: 3-8                                   [1, 768]                  [1, 768]                  --                        --\n",
       "├─Dropout: 1-2                                          [1, 768]                  [1, 768]                  --                        --\n",
       "├─Linear: 1-3                                           [1, 768]                  [1, 3]                    2,307                     True\n",
       "===========================================================================================================================================================\n",
       "Total params: 109,484,547\n",
       "Trainable params: 109,484,547\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (M): 109.48\n",
       "===========================================================================================================================================================\n",
       "Input size (MB): 0.00\n",
       "Forward/backward pass size (MB): 106.96\n",
       "Params size (MB): 437.94\n",
       "Estimated Total Size (MB): 544.90\n",
       "==========================================================================================================================================================="
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchinfo import summary\n",
    "\n",
    "dummy_input = tokenizer(\"This is a sample sentence about the stock market.\",\n",
    "                        return_tensors=\"pt\",\n",
    "                        padding=\"max_length\",\n",
    "                        truncation=True,\n",
    "                        max_length=128)\n",
    "dummy_input = {k: v.to(device) for k, v in dummy_input.items()}\n",
    "\n",
    "# show model summary\n",
    "summary(model, input_data=dummy_input, depth=3, col_names=[\"input_size\", \"output_size\", \"num_params\", \"trainable\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f5aedb1",
   "metadata": {},
   "source": [
    "# Inference (Pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b298e23e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Override the config's id2label and label2id\n",
    "label_map = {0: \"neutral\", 1: \"negative\", 2: \"positive\"}\n",
    "model.config.id2label = label_map\n",
    "model.config.label2id = {v: k for k, v in label_map.items()}\n",
    "\n",
    "pipe = pipeline(\"text-classification\", model=model, tokenizer=tokenizer)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c62663e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'label': 'positive', 'score': 0.9997484087944031}]\n"
     ]
    }
   ],
   "source": [
    "text = \"Earnings smashed expectations AAPL posts $0.89 EPS vs $0.78 est. Bullish momentum incoming! #EarningsSeason\"\n",
    "print(pipe(text)) #Output: [{'label': 'positive', 'score': 0.9997484087944031}]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1eaf8101",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              text    label     score\n",
      "0  I am not angry.  neutral  0.999642\n"
     ]
    }
   ],
   "source": [
    "texts = [\n",
    "\"I am not angry.\",\n",
    "]\n",
    "outputs = pipe(texts)\n",
    "# print(outputs)\n",
    "\n",
    "# print in df format\n",
    "output_pipe_df = pd.DataFrame({\n",
    "    'text': texts,\n",
    "    'label': [output['label'] for output in outputs],\n",
    "    'score': [output['score'] for output in outputs]\n",
    "})\n",
    "\n",
    "print(output_pipe_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "190611d0",
   "metadata": {},
   "source": [
    "# Inference (Simple Approach)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c55ea9df",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_map_ours = {0: \"neutral\", 1: \"negative\", 2: \"positive\"}\n",
    "def get_predictions_and_probs(model, inputs, label_map):\n",
    "    \"\"\"\n",
    "    Predict labels and probabilities from a model given inputs and label_map.\n",
    "\n",
    "    Args:\n",
    "        model (torch.nn.Module): Trained model.\n",
    "        inputs (dict): Tokenized inputs (from tokenizer(..., return_tensors='pt')).\n",
    "        label_map (dict): Mapping from class indices to label names.\n",
    "\n",
    "    Returns:\n",
    "        predicted_labels (List[str]): List of predicted label names.\n",
    "        probs (List[float]): List of maximum softmax probabilities.\n",
    "    \"\"\"\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.logits\n",
    "        softmax_probs = torch.nn.functional.softmax(logits, dim=-1)\n",
    "\n",
    "        max_probs, predictions = torch.max(softmax_probs, dim=-1)\n",
    "        predicted_labels = [label_map[idx.item()] for idx in predictions]\n",
    "        probs = max_probs.tolist()\n",
    "\n",
    "    return predicted_labels, probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e5fc723e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>predicted_label</th>\n",
       "      <th>probability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Earnings smashed expectations AAPL posts $0.89...</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.999748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Apple Beats Q2 Expectations With Record iPhone...</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.999796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Tesla Stock Soars as EV Deliveries Surpass For...</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.999829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Local Cat Elected Mayor of Small Town in Viral...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.999672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Researchers Develop Edible Water Bottles to Re...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.999308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>$META down 8% after missing on ad revenue. Gro...</td>\n",
       "      <td>negative</td>\n",
       "      <td>0.999700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Disappointing numbers from $NFLX — subscriber ...</td>\n",
       "      <td>negative</td>\n",
       "      <td>0.999632</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text predicted_label  \\\n",
       "0  Earnings smashed expectations AAPL posts $0.89...        positive   \n",
       "1  Apple Beats Q2 Expectations With Record iPhone...        positive   \n",
       "2  Tesla Stock Soars as EV Deliveries Surpass For...        positive   \n",
       "3  Local Cat Elected Mayor of Small Town in Viral...         neutral   \n",
       "4  Researchers Develop Edible Water Bottles to Re...         neutral   \n",
       "5  $META down 8% after missing on ad revenue. Gro...        negative   \n",
       "6  Disappointing numbers from $NFLX — subscriber ...        negative   \n",
       "\n",
       "   probability  \n",
       "0     0.999748  \n",
       "1     0.999796  \n",
       "2     0.999829  \n",
       "3     0.999672  \n",
       "4     0.999308  \n",
       "5     0.999700  \n",
       "6     0.999632  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts = [\n",
    "    \"Earnings smashed expectations AAPL posts $0.89 EPS vs $0.78 est. Bullish momentum incoming! #EarningsSeason\",\n",
    "    \"Apple Beats Q2 Expectations With Record iPhone Sales\",\n",
    "    \"Tesla Stock Soars as EV Deliveries Surpass Forecasts\",\n",
    "    \"Local Cat Elected Mayor of Small Town in Viral Social Media Sensation\",\n",
    "    \"Researchers Develop Edible Water Bottles to Reduce Plastic Waste\",\n",
    "    \"$META down 8% after missing on ad revenue. Growth slowing in key regions. Ouch. 😬📉 #Meta #FAANG\",\n",
    "    \"Disappointing numbers from $NFLX — subscriber growth stalls again. Bear case gaining steam. 🐻 #Netflix\",\n",
    "]\n",
    "inputs_ours = tokenizer(texts, padding=True, truncation=True, return_tensors=\"pt\").to(\n",
    "    device\n",
    ")\n",
    "ours_predicted_labels, ours_probs = get_predictions_and_probs(\n",
    "    model, inputs_ours, label_map_ours\n",
    ")\n",
    "\n",
    "# print in df format\n",
    "output_df = pd.DataFrame(\n",
    "    {\"text\": texts, \"predicted_label\": ours_predicted_labels, \"probability\": ours_probs}\n",
    ")\n",
    "output_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adcc52a2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
